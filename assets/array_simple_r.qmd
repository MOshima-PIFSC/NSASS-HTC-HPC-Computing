---
title: "simple_r: Submitting an array job using a text file to indicate job directories"
date: last-modified
date-format: iso
published-title: "Last updated"
author: Nicholas Ducharme-Barth
engine: knitr
execute:
    eval: false
format:
  html:
    embed-resources: true
    toc: true
    toc-location: right
    number-sections: true
    code-overflow: wrap
---

## Example description & setup

In this example we step through submitting an array job on Hera where we want to run the same job in a number of directories. In this case the job is running a simple [R script](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/example_data/simple_r/script.r) that reads in the *.csv* file stored in the directory, fits a linear model, and writes the paramter estimates to a *.csv*. We specify which directories we want to run jobs in as a part of the job-array using a [text file](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/example_data/simple_r/simple_r_v2.txt) to specify the directory path names on Hera.

The *simple_r* example can be set-up either by cloning the repository `git clone https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera.git`, or stepping through the following code:

Define relative path and create directory if needed

::: {.callout-important}
# Hard-coding alert!
Note you will have to change `proj_dir` to match your machine path and also may need to change `hera_project` from "NMFS/htc4sa/" if you are under a different HPC project.
:::

```{r}

#| echo: true
#| output: false
proj_dir = "D:/HOME/SAP/Code/noaa-hpc-hera/"
dir.create(proj_dir, recursive=TRUE)
hera_project = "NMFS/htc4sa/Nicholas.Ducharme-barth/"
```

Define directory names
```{r}

#| echo: true
#| output: false
dir_name = paste0("rep_0", 0:9)
```

Iterate across directories, create them, and then write a simple .csv file into them containing data to fit a linear model
```{r}

#| echo: true
#| output: false
for(i in seq_along(dir_name))
{
    if(!file.exists(paste0(proj_dir, "example_data_input/simple_r/", dir_name[i], "/data.csv")))
    {
        set.seed(i)
        dir.create(paste0(proj_dir, "example_data_input/simple_r/", dir_name[i]), recursive=TRUE)
        tmp = data.frame(x=1:1000)
        tmp$y = (i + (0.5*i)*tmp$x) + rnorm(1000,0,i)
        write.csv(tmp, file=paste0(proj_dir, "example_data_input/simple_r/", dir_name[i], "/data.csv"))
    }
}
```

Write a simple R script to read in the data, run a linear model, and report back the estimated parameters
```{r}

#| echo: true
#| output: false
if(!file.exists(paste0(proj_dir, "example_data_input/simple_r/script.r")))
{
    script_lines = c("tmp=read.csv('data.csv')", "fit=lm(y~x,data=tmp)", "out = data.frame(par=unname(fit$coefficients))", "write.csv(out,file='par.csv')")
    writeLines(script_lines, con=paste0(proj_dir, "example_data_input/simple_r/script.r"))
}
```

Write a text file containing the full path names for where the directories will be on Hera
```{r}

#| echo: true
#| output: false
if(!file.exists(paste0(proj_dir, "example_data_input/simple_r/simple_r_v2.txt")))
{
    dir_lines = paste0("/scratch1/", hera_project, "simple_r/", dir_name, "/")
    writeLines(dir_lines, con=paste0(proj_dir, "example_data_input/simple_r/simple_r_v2.txt"))
}
```

Compress the entire `simple_r/` directory as a tar.gz file `upload.simple_r.tar.gz`. This simplifies the number of steps needed for file transfers.
```{r}

#| echo: true
#| output: false
shell(paste0("powershell cd ", paste0(proj_dir, "example_data_input/"), ";tar -czf upload.simple_r.tar.gz simple_r "))
```

## Hera workflow

::: {.callout-important}
# Hard-coding alert!
In the following `bash` code you will need to:

1. Replace `Nicholas.Ducharme-barth` with your HPC user name.

2. Replace `NMFS/htc4sa/` your HPC project name.
:::

Open a PowerShell terminal and [connect to Hera](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/documentation/hera_doc.qmd). This terminal will be your remote workstation, call it *Terminal A*. You will be prompted for your RSA passcode.

```{bash}

#| echo: true
#| output: false
ssh -m hmac-sha2-256-etm@openssh.com Nicholas.Ducharme-barth@hera-rsa.boulder.rdhpcs.noaa.gov -p22
```
In *Terminal A* navigate to the project directory on `scratch1` and create some directories. Since `htc4sa/` is a shared directory across all project users, make a directory to save your work within this directory (.e.g., `User.Name/`). Change your working directory to this directory. We will upload our SLURM [submit script](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/example_slurm_scripts/submit_array_simple_r_v2.sh) into `submit_scripts/` and write our SLURM log files to `logs/`.
```{bash}

#| echo: true
#| output: false
cd /scratch1/NMFS/htc4sa/
```
```{bash}

#| echo: true
#| output: false
mkdir Nicholas.Ducharme-barth/
cd Nicholas.Ducharme-barth/
```
```{bash}

#| echo: true
#| output: false
mkdir submit_scripts/
```
```{bash}

#| echo: true
#| output: false
mkdir logs/
```

Open a second PowerShell terminal in the `noaa-hpc-hera` directory on your machine. This will be your local workstation, call it *Terminal B*. Use this terminal window to upload via *scp* the needed files (`example_data/upload.simple_r.tar.gz` and `example_slurm_scripts/submit_array_simple_r_v2.sh`) to Hera. The `upload.simple_r.tar.gz` will uploaded to your directory within the project directory on `scratch1` and the submit script `submit_array_simple_r_v2.sh` will be uploaded to the `submit_scripts` directory. Make sure your VPN is active when attempting to upload using the [DTN](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/documentation/hera_doc.qmd). You will be prompted for your RSA passcode after each *scp* command.

```{bash}

#| echo: true
#| output: false
scp example_data_input/upload.simple_r.tar.gz Nicholas.Ducharme-barth@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/htc4sa/Nicholas.Ducharme-barth
```
::: {.callout-important}
# Hard-coding alert!
In `submit_array_simple_r_v2.sh` you will need to change the following before you upload and run the script:

1. Line 9: `/scratch1/NMFS/htc4sa/Nicholas.Ducharme-barth/logs/` to the location you created for `logs/` above.

2. Line 10: Change to **your** email address.

3. Line 24: Make sure that this line points to the location on Hera that you uploaded `simple_r_v2.txt` to. `simple_r_v2.txt` is located in the `simple_r` directory that was uploaded as a part of `upload.simple_r.tar.gz`.

4. Line 37: Make sure that this line points to the location on Hera that you uploaded `script.r` to. `script.r` is located in the `simple_r` directory that was uploaded as a part of `upload.simple_r.tar.gz`. 
:::

```{bash}

#| echo: true
#| output: false
scp example_slurm_scripts/submit_array_simple_r_v2.sh Nicholas.Ducharme-barth@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/htc4sa/Nicholas.Ducharme-barth/submit_scripts/
```
Back in *Terminal A* untar the uploaded directory.
```{bash}
#| echo: true
#| output: false
tar -xzf upload.simple_r.tar.gz
```
Make sure files that will be read/executed have unix line endings:
```{bash}

#| echo: true
#| output: false
dos2unix simple_r/script.r simple_r/simple_r_v2.txt submit_scripts/submit_array_simple_r_v2.sh
```
Now you are ready to submit the SLURM [submission script](https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera/blob/main/example_slurm_scripts/submit_array_simple_r_v2.sh) `submit_array_simple_r_v2.sh`.
```{bash}

#| echo: true
#| output: false
sbatch submit_scripts/submit_array_simple_r_v2.sh
```
As part of this job script, it cleans the directories specified in `simple_r_v2.txt` of the input file `data.csv`. The output is a compressed *tar.gz* containing the output produced by `script.r` (`par.csv`) and `runtime.txt` which logs the job start, end, and runtime. You can check your job status using `squeue` but this job should complete in a few seconds.
```{bash}
#| echo: true
#| output: false
squeue -u Nicholas.Ducharme-barth
```
Before sending back the results you need to compress `simple_r`.
```{bash}

#| echo: true
#| output: false
tar -czf download.simple_r.tar.gz simple_r
```
Moving back to *Terminal B* you can download the results, but first you create a directory for it to be downloaded into. This can be done in R:
```{r}

#| echo: true
#| output: false
dir.create(paste0(proj_dir, "example_data_output/"), recursive=TRUE, showWarnings = FALSE)
```
Now you can use *scp* in *Terminal B* to download `download.simple_r.tar.gz` into `example_data_output/`
```{bash}

#| echo: true
#| output: false
scp Nicholas.Ducharme-barth@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/htc4sa/Nicholas.Ducharme-barth/download.simple_r.tar.gz example_data_output/
```
Move into `example_data_output/` and untar downloaded results.
```{bash}

#| echo: true
#| output: false
cd example_data_output/
```
```{bash}

#| echo: true
#| output: false
tar -xzf download.simple_r.tar.gz
```

## Process the output

In R, iterate through the sub-directories of the input and output data to extract the results of the linear model fits, and the model run time information.
```{r}

#| echo: true
#| output: false
#| code-fold: true
#| code-summary: "Show code"
library(data.table)
library(magrittr)

input_data.list = as.list(rep(NA,10))
output_data.list = as.list(rep(NA,10))
runtime_data.list = as.list(rep(NA,10))

for(i in seq_along(dir_name))
{
    # get input data
        input_data.list[[i]] = fread(paste0(proj_dir, "example_data_input/simple_r/", dir_name[i],"/data.csv")) %>%
            .[,.(x,y)] %>%
            .[,model := factor(as.character(i),levels=as.character(1:10))] %>%
            .[,.(model,x,y)]
    
    # untar results
        shell(paste0("powershell cd ", paste0(proj_dir, "example_data_output/simple_r/", dir_name[i],"/"), ";tar -xzf output.tar.gz"))

    # get output
        output_data.list[[i]] = fread(paste0(proj_dir, "example_data_output/simple_r/", dir_name[i],"/par.csv")) %>%
            .[,.(par)] %>%
            .[,model := factor(as.character(i),levels=as.character(1:10))] %>%
            .[,.(model,par)] %>%
            melt(.,id.vars="model") %>%
            .[,variable:=c("intercept","slope")] %>%
            dcast(.,model ~ variable) %>%
            merge(.,input_data.list[[i]][,.(model,x)],by="model") %>%
            .[,pred_y := intercept+slope*x] %>%
            .[,.(model,x,pred_y)]
    # get time
        runtime_data.list[[i]] = readLines(paste0(proj_dir, "example_data_output/simple_r/", dir_name[i],"/runtime.txt")) %>%
            gsub(".*?([0-9]+).*", "\\1", .) %>%
            as.numeric(.) %>%
            as.data.table(.) %>%
            setnames(.,".","time") %>%
            .[,model := factor(as.character(i),levels=as.character(1:10))] %>%
            melt(.,id.vars="model") %>%
            .[,variable:=c("start","end","runtime")] %>%
            dcast(.,model ~ variable) %>%
            .[,.(model,start,end,runtime)]
}

input_data = rbindlist(input_data.list)
output_data = rbindlist(output_data.list)
runtime_data = rbindlist(runtime_data.list)
```

The jobs started execution at `r as.POSIXct(min(runtime_data$start)[1],origin="1970-01-01")` and all finished by `r as.POSIXct(max(runtime_data$end)[1],origin="1970-01-01")` for an elapsed runtime of `r (max(runtime_data$end)[1]-min(runtime_data$start)[1])` seconds and a total computation time of `r sum(runtime_data$runtime)` seconds. Use of Hera resulted in a job completing `r round(sum(runtime_data$runtime)/(max(runtime_data$end)[1]-min(runtime_data$start)[1]),digits=2)`$\times$ faster. @fig-example-fit shows the simulated data and estimated linear fits for each model run in the job-array.

```{r}

#| echo: true
#| output: true
#| code-fold: true
#| code-summary: "Show code"
#| label: fig-example-fit
#| fig-cap: "Linear model fits from the 10 models run."
#| fig-alt: "Scatterplot of simulated x and y values as colored points, and colored lines depicting the linear model fits to the simulated data. The colors correspond to the different models that were fit in this example. The plot displays a positive, linear, and strong relationship x and y."
#| fig-width: 6
#| fig-height: 3.5
#| fig-dpi: 300
library(ggplot2)
input_data %>%
ggplot() +
geom_point(aes(x=x,y=y,fill=model),alpha=0.05,size=5,shape=21) +
geom_line(data=output_data,aes(x=x,y=pred_y,color=model),linewidth=2)
```