---
title: "Running an array of SS3 jobs on Hera"
date: last-modified
date-format: iso
published-title: "Last updated"
author: 
  - Nicholas Ducharme-Barth
  - Megumi Oshima
engine: knitr
execute:
    eval: false
    echo: true
    output: false
format:
  html:
    embed-resources: true
    toc: true
    toc-location: right
    number-sections: true
    code-overflow: wrap
---

Similar to the [array_lm](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/array_hera.html) example, this example also sets up running an array job on Hera. As before, we will use a `*.txt` to indicate which directories we want to run jobs in as a part of our array.

There are a few main differences that serve to illustrate useful modifications to the workflow:

* in this case we will run [Stock Synthesis](https://github.com/nmfs-stock-synthesis/stock-synthesis) (SS3) on all models in the SS testing suite to conduct a retrospective analysis;
* we will set up the job array to run using the *gnu* parallel utility in order to more effectively implement an HTC type workflow in an HPC system;
* we will run our jobs within a software container;
* lastly, we will define *variables* to be passed between job submission and job execution scripts to ensure that the correct output is produced.

The *hera/ss3* example can be set-up either by cloning the repository `git clone https://github.com/MOshima-PIFSC/NSASS-HTC-HPC-Computing.git`, or stepping through the following code:

::: {.callout-important}
# Coding alert!
Note: throughout this tutorial we are using **User.Name** as a stand-in for your actual username and **NMFS/project_name** as a stand-in for your project. In all cases, replace **User.Name** with your actual user name and **NMFS/project_name** with your specific project name. 
:::

## Build software container

Software containers allow for portable, reproducible research by allowing researchers to set-up a software environment to their exact spefications and being able to run it on any Linux system. The [Apptainer](https://apptainer.org/) container system is widely used across HPC/HTC systems, and make it easy to build a container from a definition file. Running a job within a container means that you are able to replicate an identical software environment in any location with Apptainer installed, no matter the native operating system, software and installed packages. The Apptainer container can be built from any Linux machine with Apptainer installed, including the [Open Science Grid](https://osg-htc.org/) (OSG) access points. Here we walk through the steps needed to build a Linux (Ubuntu 20.04) container containing Stock Synthesis (version 3.30.22.1), R (version 4.4.0) and the R packages r4ss, ss3diags, data.table, magrittr, and mvtnorm from a definition file, [linux-r4ss-v4.def](https://github.com/MOshima-PIFSC/NSASS-HTC-HPC-Computing/blob/main/apptainer/linux-r4ss-v4.def). In this case we will show the steps needed to build the container using the OSG access point as our Linux virtual machine (VM), though many may not be needed if working from an alternative Linux VM.

::: {.callout-important}
# Coding alert!
Note: you will have to change **apXX** to match your OSG access point (e.g., `ap20` or `ap21`).
:::

The first step is to [log onto your OSG access point](https://portal.osg-htc.org/documentation/overview/account_setup/connect-access/) via ssh using a Terminal/PowerShell window and make a directory to build your container in this case `singularity`[^1].

[^1]: This directory can be named anything that you like, in this case `singularity` is a legacy name from an earlier version of the code written before Singularity changed its name to Apptainer.

```{bash}
#| eval: false
#| echo: true
#| output: false
ssh User.Name@apXX.uc.osg-htc.org
mkdir -p singularity/linux_r4ss
```

Using a second Terminal/PowerShell window, navigate to the directory that you cloned the [`NSASS-HTC-HPC-Computing`](https://github.com/MOshima-PIFSC/NSASS-HTC-HPC-Computing) repo into and upload the definition file (`linux-r4ss-v4.def`) to the directory you just created on OSG.

```{bash}
#| eval: false
#| echo: true
#| output: false
scp apptainer/linux-r4ss-v4.def User.Name@apXX.uc.osg-htc.org:/home/User.Name/singularity/linux_r4ss
```

Back in your first Terminal/PowerShell window manoeuvre into the directory, and build the container[^2]. The second line of code is what builds the Singularity Image File (*`.sif`*) and takes two arguments: the name of the output *`.sif`* file and the input definition file (*`.def`*).

[^2]: This may take ~10-15 minutes depending on how long it takes to install R packages.

```{bash}
#| eval: false
#| echo: true
#| output: false
cd singularity/linux_r4ss
apptainer build linux-r4ss-v4.sif linux-r4ss-v4.def
```

Using the second Terminal/PowerShell window, download the Singularity Image File (*`.sif`*) so that it can be uploaded for use on the NOAA Hera HPC system.

```{bash}
#| eval: false
#| echo: true
#| output: false
scp User.Name@apXX.uc.osg-htc.org:/home/User.Name/singularity/linux_r4ss/linux-r4ss-v4.sif apptainer/
```


## Setup data inputs and directories

Given that our example is to run a 4-year retrospective analysis for each of the SS3 test models, the next step is downloading the SS3 test models from the [nmfs-stock-synthesis/test-models](https://github.com/nmfs-stock-synthesis/test-models/tree/main) Github repo. Once you've downloaded the test models, copy the `models/` directory into a new example directory `ss3/inputs/` within the `NSASS-HTC-HPC-Computing/examples/hera/` directory on your machine. If you cloned the [`NSASS-HTC-HPC-Computing`](https://github.com/MOshima-PIFSC/NSASS-HTC-HPC-Computing) repo, the SS3 test models will already be in the correct location.

For the sake of example the job array will be set-up to run each retrospective peel (e.g., -0 years, -1 year, ... , -4 years of data) as individual jobs in the job array. This is more efficient in a true HTC environment such as OSG however on Hera it could make more sense to bundle the initial model run and subsequent retrospective peels as a single job. We will store the results of each retrospective peel in its own directory. The directories on Hera will be listed in a text file, and we will use this text file to launch jobs on Hera (as a part of the job array) in each of the named directories.

Let us define that text file using R.

1. Define a relative path, we are starting from the root directory of this project.

```{r}
#| eval: true
#| code-fold: true
proj_dir = this.path::this.proj()
hera_project = "NMFS/project_name/User.Name/"
```

2. Write a text file containing the full path names for where the directories will be on Hera.
```{r}
#| eval: true
#| code-fold: true
test_models=list.dirs(paste0(proj_dir,"/examples/hera/ss3/inputs/models/"),recursive=FALSE,full.names=FALSE)
retro_peels=0:4

# define scenarios
scenario_df = expand.grid(model=test_models,peel=retro_peels)
scenario_df$run_id = 1:nrow(scenario_df)
scenario_df = scenario_df[,c(3,1,2)]
scenario_df$run_id = ifelse(scenario_df$run_id<10,paste0(0,scenario_df$run_id),as.character(scenario_df$run_id))

# write text file
hera_dir_lines = paste0("/scratch1/", hera_project, "examples/ss3/", apply(scenario_df,1,paste0,collapse="_"), "/")
writeLines(hera_dir_lines, con=paste0(proj_dir, "/examples/hera/ss3/inputs/hera_job_directories.txt"))
```
3. Compress the `ss3/inputs/` directory as a tar.gz file `upload.example-ss3.tar.gz`. This simplifies the number of steps needed for file transfers.
```{r}
#| eval: false
#| code-fold: true
shell(paste0("powershell cd ", file.path(proj_dir, "examples", "hera", "ss3"), ";tar -czf upload.example-ss3.tar.gz inputs/ "))
```
