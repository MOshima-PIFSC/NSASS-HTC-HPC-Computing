---
title: "Operationalizing available research computing resources for stock assessment"
format: 
 revealjs:
  theme: [default, customizations/presentation-custom.scss]
  footer: "National Stock Assessment Science Seminar"
  logo: static/noaa-fisheries-logo.png
  css: customizations/logo.css
  slide-number: true
  revealjs-plugins:
  - codewindow
  mermaid-format: svg
author: Nicholas Ducharme-Barth and Megumi Oshima
date: Nov 5, 2024
embed-resources: true
bibliography: customizations/osg.bib
---

## What?

</br>

::: {.fragment .fade-in fragment-index=1}
::: {.fragment .semi-fade-out fragment-index=2}
Research computing is the collection of computing, software, storage resources and services that allows for data analysis at scale.
:::
:::

</br>

::: {.fragment .fade-in fragment-index=2}
::: {.fragment .strike fragment-index=3}
In our particular case we are interested in leverging research computing to augment stock assessment worflows.
:::
:::

::: {.fragment .fade-in fragment-index=3}
[Run more/bigger models in less time]{.blue}
:::

## Why?

::: {.fragment .semi-fade-out fragment-index=3}
::: {.fragment .fade-in fragment-index=1}
:::{.absolute left="0%" top="12.5%" style="font-size:0.7em;"}
Improve efficiency by running 10s - 1000s of models ['simultaneously']{.blue}.
:::
:::
:::

::: {.fragment .fade-in fragment-index=2}
![](static/swo-runtime.png){.absolute top="20%" height="75%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
![](static/wcpfc-logo.png){.absolute top="21%" right="15%" width="14%" style="max-height: unset; max-width: unset;"}
![](static/spc-logo.png){.absolute top="30%" right="15%" width="14%" style="max-height: unset; max-width: unset;"}

:::{.absolute left="10%" right="50%" top="25%" style="font-size:0.65em;"}
2021 Southwest Pacific Ocean swordfish stock assessment
:::
:::

::: {.fragment .fade-in fragment-index=3}
::: {.absolute left="10%" top="55%" right="40%" style="font-size:0.85em; padding: 0.5em 1em; background-color: rgba(255, 255, 255, .85); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
[9,300]{.blue} model runs totalling [~46 months]{.blue} of computation time. 
:::
:::

## Why?

</br>

::: {.fragment .fade-in fragment-index=1}
::: {.fragment .semi-fade-out fragment-index=2}
- Efficiency
:::
:::

::: {.fragment .fade-in fragment-index=2}
::: {.fragment .semi-fade-out fragment-index=3}
- Knowledge acquisition
:::
:::

::: {.fragment .fade-in fragment-index=3}
::: {.fragment .semi-fade-out fragment-index=7}
- Automation, transparency, [reproducibility & portability]{.fragment .hl-blue fragment-index=4}
:::
:::

::: {.fragment .fade-in fragment-index=7}
::: {.fragment .semi-fade-out fragment-index=8}
- Multi-model inference
:::
:::

::: {.fragment .fade-out fragment-index=7}
::: {.fragment .fade-in fragment-index=5}
::: {.absolute left="10%" bottom="10%" style="font-color: #ffffff; font-size:1.25em; padding: 0.5em 1em; background-color: #0085CA; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Software containers]{.bg} 
:::
:::
::: {.fragment .fade-in fragment-index=6}
![](static/apptainer-logo.png){.absolute bottom="10%" right="10%" width="15%" style="max-height: unset; max-width: unset;"}
:::
:::

::: {.fragment .fade-in fragment-index=8}
::: {.absolute right="25%" bottom="40%" style="font-color: #ffffff; font-size:1.75em; padding: 0.5em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Better science]{.bg}
:::
:::

<!-- ::: {.absolute left="10%" top="40%" style="font-color: #ffffff; font-size:2em; padding: 0.25em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Is this 'time-savings' worth it?]{.bg} 
::: -->

## How?

::: columns
::: {.column width="45%"}

::: {.fragment .fade-out fragment-index=9}

[High-throughput computing (HTC)]{.blue}

::: {.fragment .semi-fade-out fragment-index=3}
::: {.fragment .fade-in fragment-index=1}
- Set-up to handle running many jobs simultaneously
:::
::: {.fragment .fade-in fragment-index=2}
- Ideal for running short, small, independent (embarrassingly parallel) jobs. 
:::
:::
:::
:::

::: {.column width="45%"}
::: {.fragment .fade-in fragment-index=6}

[High-performance computing (HPC)]{.blue}

::: {.fragment .semi-fade-out fragment-index=9}
::: {.fragment .fade-in fragment-index=7}
- Can handle HTC workflows (in theory)
:::

::: {.fragment .fade-in fragment-index=8}
- Can also handle long running, large, multi-processor jobs (true parallel processing)
:::
:::
:::
:::
:::

::: {.fragment .fade-out fragment-index=6}
::: {.fragment .fade-in fragment-index=3}
::: {.absolute left="45%" top="25%" right="0%" style="font-size:0.6em; padding: 0.5em 1em; background-color: rgba(255, 255, 255, 1); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
**2024 North Pacific shortfin mako shark assessment**:
Used HTC resources to complete [~4 months]{.fragment .hl-cur-blue fragment-index=4} months of Bayesian simulation-estimation evaluations (18,000 model runs using [RStan](https://mc-stan.org/users/interfaces/rstan){preview-link="true"}) in [~3 hours]{.fragment .hl-cur-blue fragment-index=5} (1027 $\times$ faster) during a working group meeting.
:::

![](static/stan-logo.png){.absolute top="32.5%" right="-15%" width="10%" style="max-height: unset; max-width: unset;"}

:::
:::

::: {.fragment .fade-in fragment-index=9}
::: {.absolute left="0%" top="35%" right=60% style="font-size:0.6em; padding: 0.5em 1em; background-color: rgba(255, 255, 255, 1); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
**Example**: [Fitting large spatiotemporal model in R](https://arxiv.org/abs/2304.09442){preview-link="true"} using TMB required [128 CPUs & 1TB RAM]{.blue}.
:::
:::

## How?

::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
::: {.absolute right="25%" bottom="40%" style="font-color: #ffffff; font-size:1.5em; padding: 0.5em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Available resources]{.bg}
:::
:::
:::

::: columns
::: {.column width="45%"}

::: {.fragment .fade-in fragment-index=2}
[High-throughput computing (HTC)]{.blue}
:::

:::

::: {.column width="45%"}

::: {.fragment .fade-in fragment-index=3}
[High-performance computing (HPC)]{.blue}
:::
:::
:::

::: {.fragment .fade-in fragment-index=2}
![](static/osg-logo.png){.absolute top="35%" left="0%" height="25%" style="max-height: unset; max-width: unset;"}
:::

::: {.fragment .fade-in fragment-index=3}
![](static/noaa-hera.jpg){.absolute top="35%" right="15%" height="30%" style="border: 1px solid #323C46; max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute right="10%" bottom="32%" left=45% style="font-size:0.4em;"}
[Photo credit: NOAA]{.hide-text}
:::
:::

::: {.fragment .fade-in fragment-index=2}
::: {.absolute left="0%" bottom="10%" right=55%}
[OpenScienceGrid](https://osg-htc.org/){preview-link="true"} (OSG): OSPool
:::
:::

::: {.fragment .fade-in fragment-index=3}
::: {.absolute right="0%" bottom="15%" left=55%}
[NOAA Hera](https://docs.rdhpcs.noaa.gov/){preview-link="true"}
:::
:::

## How? {.smaller}

::: columns
::: {.column width="45%"}
[OpenScienceGrid (OSG)]{.blue}

::: {.fragment .semi-fade-out fragment-index=5}
::: {.fragment .fade-in fragment-index=1}
- Uses [HTCondor](https://htcondor.org/){preview-link="true"} distributed computing network [(no shared file system between compute nodes)]{.fragment .hl-blue fragment-index=2} to implement HTC workflows
:::


::: {.fragment .fade-in fragment-index=3}
- [Free to use]{.blue} for US based researchers affiliated with academic/government organization and using OSG for research/education efforts
:::

::: {.fragment .fade-in fragment-index=4}
- [Should not be used to analyze protected data]{.blue}
:::
:::

:::
::: {.column width="45%"}
[NOAA Hera]{.blue}

::: {.fragment .semi-fade-out fragment-index=12}
::: {.fragment .fade-in fragment-index=6}
- Uses [Slurm](https://slurm.schedmd.com/documentation.html){preview-link="true"} to schedule HPC [(or HTC)]{.fragment .hl-blue fragment-index=7} workflows
:::


::: {.fragment .fade-in fragment-index=8}
- [Shared file system between compute nodes]{.blue}
:::

::: {.fragment .fade-in fragment-index=9}
- [Allocation determines access]{.blue}
:::

::: {.fragment .fade-in fragment-index=10}
- NOAA resource so [no restrictions]{.fragment .hl-blue fragment-index=11} on acceptable use/analyzing protected data if working on mission related tasks
:::
:::

:::
:::

::: {.fragment .fade-in fragment-index=12}
::: {.absolute left="10%" right="25%" bottom="27.5%" top="55%" style="font-size:1em; padding: 0.5em 1em; background-color: rgba(255, 255, 255, 1); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
Both use software containers 
:::
:::

::: {.fragment .fade-in fragment-index=12}
![](static/apptainer-logo.png){.absolute bottom="27.5%" right="30%" width="10%" style="max-height: unset; max-width: unset;"}
:::

::: {.fragment .fade-out fragment-index=3}
::: {.fragment .fade-in fragment-index=1}
![](static/htcondor-logo.png){.absolute top="50%" left="5%" width="25%" style="max-height: unset; max-width: unset;"}
:::
:::

::: {.fragment .fade-out fragment-index=8}
::: {.fragment .fade-in fragment-index=6}
![](static/slurm-logo.png){.absolute top="35%" left="60%" width="15%" style="max-height: unset; max-width: unset;"}
:::
:::

## Software containers

<br/>

::: {.fragment .semi-fade-out fragment-index=3}
Many may already be using containers such as [GitHub Codespaces]{.fragment .hl-cur-black fragment-index=1} or [Posit Workbench]{.fragment .hl-cur-pc-orange fragment-index=2} in existing cloud-based workflows
:::

::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
![](static/github-logo.png){.absolute bottom="27.5%" left="40%" width="15%" style="max-height: unset; max-width: unset;"}
:::
:::

::: {.fragment .fade-out fragment-index=3}
::: {.fragment .fade-in fragment-index=2}
![](static/posit-logo.png){.absolute bottom="27.5%" left="40%" width="15%" style="max-height: unset; max-width: unset;"}
:::
:::

::: {.fragment .fade-in fragment-index=3}
- [Application:]{.blue} set up identical, custom software environments on OSG and Hera
:::

::: {.fragment .fade-in fragment-index=4}
- [Application:]{.blue} use to "version" analyses by "freezing" packages/libraries
:::

## Software containers{.smaller}

::: columns
::: {.column width="55%"}

### [Apptainer](https://apptainer.org/){preview-link="true"}

::: {.fragment .fade-in fragment-index=1}
- Secure, portable and reproducible software container for Linux operating systems
:::


::: {.fragment .fade-in fragment-index=2}
- Easy to use
:::

::: {.fragment .fade-in fragment-index=3}
- Doesn't require *root* privileges to build making it ideal for HTC/HPC environments
:::

::: {.fragment .fade-in fragment-index=4}
- Plays nice with existing containers (e.g., [Docker]{.fragment .hl-cur-mb-blue fragment-index=4})
:::

:::
:::

![](static/apptainer-logo.png){.absolute top="0%" right="0%" width="15%" style="max-height: unset; max-width: unset;"}

::: {.fragment .fade-in fragment-index=4}
![](static/docker-logo-blue.png){.absolute bottom="15%" right="0%" width="20%" style="max-height: unset; max-width: unset;"}
:::

## Apptainer

Let's look at an example (`linux-r4ss-v4.def`):

::: {.fragment .fade-in}
::: {.absolute top="23%" bottom="2%" left="0%" right="10%"}
```{.dockerfile code-line-numbers="|1-2|37-39|44-47|48-49|54-56|59|66"}
Bootstrap: docker
From: ubuntu:20.04

%post
    TZ=Etc/UTC && \
    ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && \
    echo $TZ > /etc/timezone
    apt update -y
    apt install -y \
        tzdata \
        curl \
        dos2unix

    apt-get update -y
    apt-get install -y \
            build-essential \
            cmake \
            g++ \
            libssl-dev \
            libssh2-1-dev \
            libcurl4-openssl-dev \
            libfontconfig1-dev \
            libxml2-dev \
            libgit2-dev \
            wget \
            tar \
            coreutils \
            gzip \
            findutils \
            sed \
            gdebi-core \
            locales \
            nano
    
    locale-gen en_US.UTF-8

    export R_VERSION=4.4.0
    curl -O https://cdn.rstudio.com/r/ubuntu-2004/pkgs/r-${R_VERSION}_1_amd64.deb
    gdebi -n r-${R_VERSION}_1_amd64.deb

    ln -s /opt/R/${R_VERSION}/bin/R /usr/local/bin/R
    ln -s /opt/R/${R_VERSION}/bin/Rscript /usr/local/bin/Rscript

    R -e "install.packages('remotes', dependencies=TRUE, repos='http://cran.rstudio.com/')"
    R -e "install.packages('data.table', dependencies=TRUE, repos='http://cran.rstudio.com/')"
    R -e "install.packages('magrittr', dependencies=TRUE, repos='http://cran.rstudio.com/')"
    R -e "install.packages('mvtnorm', dependencies=TRUE, repos='http://cran.rstudio.com/')"
    R -e "remotes::install_github('r4ss/r4ss')"
    R -e "remotes::install_github('PIFSCstockassessments/ss3diags')"

    NOW=`date`
    echo 'export build_date=$NOW' >> $SINGULARITY_ENVIRONMENT

    mkdir -p /ss_exe
    curl -L -o /ss_exe/ss3_linux https://github.com/nmfs-ost/ss3-source-code/releases/download/v3.30.22.1/ss3_linux
    chmod 755 /ss_exe/ss3_linux

%environment
    export PATH=/ss_exe:$PATH
    
%labels
    Author nicholas.ducharme-barth@noaa.gov
    Version v0.0.4

%help
    This is a Linux (Ubuntu 20.04) container containing Stock Synthesis (version 3.30.22.1), R (version 4.4.0) and the R packages r4ss, ss3diags, data.table, magrittr, and mvtnorm.
```
:::
:::

## Apptainer

Let's look at an example (`linux-r4ss-v4.def`):

Build on Linux system with Apptainer installed.

::: {.codewindow .terminal .absolute top="40%"}

```{.bash}
apptainer build linux-r4ss-v4.sif linux-r4ss-v4.def
```
:::

## Let's walk through an example {.smaller}

::: {.fragment .fade-in fragment-index=1}
In this case we will use [NOAA Hera](https://docs.rdhpcs.noaa.gov/systems/hera_user_guide.html){preview-link="true"} to conduct a quick retrospective analysis on all models in the [Stock Synthesis](https://github.com/nmfs-ost/ss3-source-code) (SS3) [testing suite](https://github.com/nmfs-ost/ss3-test-models).
:::

::: {.fragment .fade-in fragment-index=1}
![](static/ss3-test-models.png){.absolute top="27.5%" left="5%" width="90%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
:::

::: {.fragment .fade-in fragment-index=2}
::: {.absolute bottom="5%" width="100%" }
More complete documentation of this example can be found on our [GitHub website](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/ss3-hera.html){preview-link="true"}.
:::
:::

## Workflow  

1.  [Create container]{.fragment .fade-body fragment-index=1}

::: {.fragment .fade-in fragment-index=2}
2.  Create files/scripts
:::

::: {.fragment .fade-in fragment-index=3}
3.  Upload files
:::

::: {.fragment .fade-in fragment-index=4}
4.  Submit jobs
:::

::: {.fragment .fade-in fragment-index=5}
5.  Download files back to local machine
:::

## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}

:::


::: {.absolute left="40%" right="0%" top="40%" style="font-color: #323C46; font-size:0.7em; padding: 0.25em 1em; background-color: #C6E6F0; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}
[IDE:]{.blue} Develop and make job files/scripts 
:::

::: {.fragment .fade-in}
::: {.absolute left="40%" right="0%" top="55%" style="font-size:0.65em;"}
::: {.callout-important }

Note that you will need to replace [User.Name]{.blue} with your actual user name and [project_name]{.blue} with your specific project name in the following code.

:::
:::
:::

## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::


::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
[0.]{.blue} Text file specifying directories to run jobs in. 
:::

::: {.codewindow .absolute top="15%" left="30%" right="0%" bottom="0%" style="font-size: 0.4em;"}
hera_job_directories.txt
```{.css}
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/01-BigSkate_2019-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/02-Empirical_Wtatage_Age_Selex-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/03-growth_timevary-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/04-Hake_2018-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/05-Hake_2019_semi_parametric_selex-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/06-platoons-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/07-Sablefish2015-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/08-Simple-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/09-Simple_Lorenzen_tv_trend-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/10-Simple_NoCPUE-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/11-Simple_with_Discard-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/12-Simple_with_DM_sizefreq-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/13-Spinydogfish_2011-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/14-tagging_mirrored_sel-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/15-three_area_nomove-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/16-two_morph_seas_areas-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/17-vermillion_snapper-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/18-vermillion_snapper_F4-0/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/19-BigSkate_2019-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/20-Empirical_Wtatage_Age_Selex-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/21-growth_timevary-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/22-Hake_2018-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/23-Hake_2019_semi_parametric_selex-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/24-platoons-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/25-Sablefish2015-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/26-Simple-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/27-Simple_Lorenzen_tv_trend-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/28-Simple_NoCPUE-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/29-Simple_with_Discard-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/30-Simple_with_DM_sizefreq-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/31-Spinydogfish_2011-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/32-tagging_mirrored_sel-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/33-three_area_nomove-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/34-two_morph_seas_areas-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/35-vermillion_snapper-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/36-vermillion_snapper_F4-1/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/37-BigSkate_2019-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/38-Empirical_Wtatage_Age_Selex-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/39-growth_timevary-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/40-Hake_2018-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/41-Hake_2019_semi_parametric_selex-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/42-platoons-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/43-Sablefish2015-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/44-Simple-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/45-Simple_Lorenzen_tv_trend-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/46-Simple_NoCPUE-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/47-Simple_with_Discard-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/48-Simple_with_DM_sizefreq-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/49-Spinydogfish_2011-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/50-tagging_mirrored_sel-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/51-three_area_nomove-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/52-two_morph_seas_areas-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/53-vermillion_snapper-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/54-vermillion_snapper_F4-2/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/55-BigSkate_2019-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/56-Empirical_Wtatage_Age_Selex-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/57-growth_timevary-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/58-Hake_2018-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/59-Hake_2019_semi_parametric_selex-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/60-platoons-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/61-Sablefish2015-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/62-Simple-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/63-Simple_Lorenzen_tv_trend-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/64-Simple_NoCPUE-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/65-Simple_with_Discard-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/66-Simple_with_DM_sizefreq-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/67-Spinydogfish_2011-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/68-tagging_mirrored_sel-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/69-three_area_nomove-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/70-two_morph_seas_areas-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/71-vermillion_snapper-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/72-vermillion_snapper_F4-3/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/73-BigSkate_2019-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/74-Empirical_Wtatage_Age_Selex-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/75-growth_timevary-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/76-Hake_2018-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/77-Hake_2019_semi_parametric_selex-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/78-platoons-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/79-Sablefish2015-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/80-Simple-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/81-Simple_Lorenzen_tv_trend-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/82-Simple_NoCPUE-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/83-Simple_with_Discard-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/84-Simple_with_DM_sizefreq-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/85-Spinydogfish_2011-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/86-tagging_mirrored_sel-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/87-three_area_nomove-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/88-two_morph_seas_areas-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/89-vermillion_snapper-4/
/scratch1/NMFS/project_name/User.Name/examples/ss3/output/90-vermillion_snapper_F4-4/
```
:::

## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::


::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
[1.]{.blue} Prepare files for Slurm job execution, specify job requirements and submit the parallel jobs. 
:::

::: {.codewindow .terminal .absolute top="15%" left="30%" right="0%" bottom="0%" style="font-size: 0.4em;"}
parallel-submit.sh
```{.bash}
#!/bin/bash

# prep files for slurm job execution
mkdir ./logs
dos2unix ./inputs/hera_job_directories.txt
dos2unix ./slurm_scripts/parallel-job-exec.sh
chmod 777 ./slurm_scripts/parallel-job-exec.sh

# make directory structure
# recursively (mkdir -p) makes a new directory for each line in hera_job_directories.txt
xargs -d '\n' mkdir -p -- < ./inputs/hera_job_directories.txt

# Slurm job submission variables
# -A project name
# -t time requested (minutes)
# -q queue type: batch (billed allocation) or windfall
# -N nodes requested (leave at 1 since requesting additional nodes with each line)
# -j number of jobs to run in parallel per node (restricted by number of total CPUs and available RAM)
# seq job ids to run on each node (this can be greater than -j but only -j will be run at a time so the more job ids assigned to the node the longer they will wait to be executed)
sbatch -A project_name -t 60 -q batch -N 1 --wrap 'set -x; parallel -j 30 -S `scontrol show hostnames "$SLURM_JOB_NODELIST"|paste -sd,` `pwd`/slurm_scripts/parallel-job-exec.sh `pwd` ::: `seq 0 29`; report-mem'
sbatch -A project_name -t 60 -q batch -N 1 --wrap 'set -x; parallel -j 30 -S `scontrol show hostnames "$SLURM_JOB_NODELIST"|paste -sd,` `pwd`/slurm_scripts/parallel-job-exec.sh `pwd` ::: `seq 30 59`; report-mem'
sbatch -A project_name -t 60 -q batch -N 1 --wrap 'set -x; parallel -j 30 -S `scontrol show hostnames "$SLURM_JOB_NODELIST"|paste -sd,` `pwd`/slurm_scripts/parallel-job-exec.sh `pwd` ::: `seq 60 89`; report-mem'
```
:::

## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::


::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
[2.]{.blue} Define variables to be passed to the software container and a bash wrapper script. 
:::

::: {.codewindow .terminal .absolute top="15%" left="30%" right="0%" bottom="0%" style="font-size: 0.4em;"}
parallel-job-exec.sh
```{.bash}
#!/bin/bash
# read directories from a file list

pwd; hostname; date

cd $1
export SLURM_ARRAY_TASK_ID=$2

echo $SLURM_ARRAY_TASK_ID

# define current directory
cwd=$(pwd)

# define paths for singularity container
singularity_container=${cwd}/linux-r4ss-v4.sif

# define variables and paths here to avoid hard coding insider the wrapper script
job_wrapper_script=${cwd}/slurm_scripts/wrapper-r.sh
dir_file=${cwd}/inputs/hera_job_directories.txt
r_script=${cwd}/slurm_scripts/ss3-example-calcs.r
input_data_path=${cwd}/inputs/models/
r_script_name=ss3-example-calcs.r

# change permissions on scripts to allow it to run
chmod 777 $job_wrapper_script
dos2unix $job_wrapper_script
chmod 777 $r_script
dos2unix $r_script

# run bash wrapper script within singularity environment
singularity exec $singularity_container $job_wrapper_script $SLURM_ARRAY_TASK_ID $dir_file $r_script $input_data_path $r_script_name >& logs/out-parallel.$SLURM_ARRAY_TASK_ID
```
:::


## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::


::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
[3.]{.blue} Control file I/O to the R script, execute the R script, conduct job timing and package outputs. 
:::

::: {.codewindow .terminal .absolute top="15%" left="30%" right="0%" bottom="0%" style="font-size: 0.4em;"}
wrapper-r.sh
```{.bash}
#!/bin/bash
echo "Running on host `hostname`"

# rename variables passed into the script
slurm_array_task_id=$1
dir_file=$2

# create an array with all data directories
line_index=$(($slurm_array_task_id+1))
echo ${line_index}
echo $dir_file
rep_dir=$(sed -n ${line_index}p $dir_file) 
echo $rep_dir

# change to target directory
cd ${rep_dir}

# make working directory
mkdir -p working/
cd working/

# copy files to working/
cp $3 .

# define variables for R script
input_data_path=$4

# begin calcs
start=`date +%s`
Rscript $5 $rep_dir $input_data_path 

# end of calcs book-keeping
end=`date +%s`
runtime=$((end-start))
echo $runtime
echo Start $start >  runtime.txt
echo End $end >> runtime.txt
echo Runtime $runtime >> runtime.txt

# Create empty file so that it does not mess up when repacking tar
touch End.tar.gz
# only pack up certain items
tar -czf End.tar.gz ss_report.RData runtime.txt 
# move tar out of working/
cd ..
mv working/End.tar.gz .
# delete working/
rm -r working/
```
:::

## Workflow - Create files/scripts

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="5%" top="15%" left="30%" right="0%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::


::: {.absolute left="7.5%" top="37.5%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
[4.]{.blue} Calculation script modifies SS3 input files, executes SS3 model run and conducts post-processing of output within R. 
:::

::: {.codewindow .r .absolute top="15%" left="30%" right="0%" bottom="0%" style="font-size: 0.4em;"}
ss3-example-calcs.r
```{.r}
# where is the job executing
    print(getwd())

# load packages
    library(r4ss)

# get args from bash environment
    args = commandArgs(trailingOnly = TRUE)
    print(args)

# get scenario
    scenario = tail(strsplit(args[1],"/")[[1]],n=1)
    model = strsplit(scenario,"-")[[1]][2]
    peel = as.numeric(strsplit(scenario,"-")[[1]][3])

# copy model files
    model_files = list.files(paste0(args[2],model,"/"),full.names=TRUE)
    file.copy(from=model_files,to=getwd())

# modify starter
    tmp_starter = SS_readstarter()
    tmp_starter$retro_yr = -peel

# write files
    SS_writestarter(tmp_starter, overwrite = TRUE)

# run stock synthesis
    run(exe="ss3_linux")

# extract model output
    ss_report = try(SS_output(dir=getwd()),silent=TRUE) 

# save output
    save(ss_report,file="ss_report.RData")
```
:::

## Workflow - Upload files

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute left="7.5%" top="55%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
 
:::

::: {.absolute bottom="25%" top="30%" left="50%" right="7.5%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

## Workflow - Upload files

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2-->H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1~~~H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute left="7.5%" top="55%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
 
:::

::: {.absolute bottom="25%" top="30%" left="50%" right="7.5%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

::: {.codewindow .terminal .absolute top="55%" left="10%" style="font-size: 0.4em;"}
Terminal A
```{.bash}
ssh -m hmac-sha2-256-etm@openssh.com User.Name@hera-rsa.boulder.rdhpcs.noaa.gov -p22
```
:::

## Workflow - Upload files

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2-->H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1-->H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute left="7.5%" top="55%" right="75%" bottom="30%" style="font-color: #323C46; font-size:0.5em; background-color: #e9f3f6;"}
 
:::

::: {.absolute bottom="25%" top="30%" left="70%" right="7.5%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

::: {.codewindow .terminal .absolute top="57.5%" left="0%" style="font-size: 0.4em;"}
Terminal A
```{.bash}
# navigate to project directory
cd /scratch1/NMFS/project_name/
# create new directory
mkdir User.Name/
# navigate into new directory
cd User.Name/
# create directory for SLURM scripts and logs
mkdir -p examples/ss3/
```
:::

## Workflow - Upload files

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3-->H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1-->H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::


::: {.absolute bottom="25%" top="30%" left="70%" right="7.5%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

::: {.codewindow .terminal .absolute top="75%" left="0%" right="0%" style="font-size: 0.4em;"}
Terminal B
```{.bash}
scp -o MACs=hmac-sha2-256-etm@openssh.com examples/hera/ss3/upload.example-ss3.tar.gz User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/project_name/User.Name/examples/ss3/
scp -o MACs=hmac-sha2-256-etm@openssh.com apptainer/linux-r4ss-v4.sif User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/project_name/User.Name/examples/ss3/
```
:::

## Workflow - Submit jobs

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2-->H1
L3~~~H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1-->H2_1
H1-->H2_2
H1-->H2_3

H1-->H3

H3<-->H2_1
H3<-->H2_2
H3<-->H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::


::: {.codewindow .terminal .absolute top="55%" left="0%" style="font-size: 0.4em;"}
Terminal A
```{.bash}
chmod 777 slurm_scripts/parallel-submit.sh
dos2unix slurm_scripts/parallel-submit.sh
./slurm_scripts/parallel-submit.sh
```
:::

## Workflow - Download results

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart LR
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2~~~H1
L3<-->H1
subgraph Hera [Hera]
H1([Login node])
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H2_3[/Compute node: 3/]
H3[("scratch1/")]
end
H1~~~H2_1
H1~~~H2_2
H1~~~H2_3

H1<-->H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
style Local stroke-width:3px
style Hera stroke-width:3px,stroke-dasharray: 5 5
```
:::

::: {.absolute bottom="25%" top="30%" left="70%" right="7.5%" style="border: 1px solid #e9f3f6; background-color: #e9f3f6; max-height: unset; max-width: unset;"}

:::

::: {.codewindow .terminal .absolute top="75%" left="0%" right="0%" style="font-size: 0.4em;"}
Terminal B
```{.bash}
scp -o MACs=hmac-sha2-256-etm@openssh.com -r User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/project_name/User.Name/examples/ss3/output/ examples/hera/ss3/
```
:::

## Workflow - OSG

::: {.absolute bottom="5%" top="15%" width="100%" style="max-height: unset; max-width: unset;"}
```{mermaid}
%%{
  init: {
    "theme": "base",
    "themeVariables": {
      "background": "#f4f4f4",
      "primaryColor": "#0085CA",
      "primaryTextColor": "#e9f3f6",
      "primaryBorderColor": "#003087",
      "lineColor": "#002364",
      "clusterBkg": "#e9f3f6",
      "clusterBorder": "#323C46",
      "titleColor": "#002364"
    }
  }
}%%
flowchart TD
subgraph Local
L1([IDE])
L2([Terminal A: ssh])
L3([Terminal B: scp])
end
L2<-->H1
L3<-->H1
subgraph OSG [OSG]
H1([Access point])
H3[(File storage)]
end
subgraph OSPool1 [OSPool 1]
H2_1[/Compute node: 1/]
H2_2[/Compute node: 2/]
H3_1[(File storage: 1)]
H3_2[(File storage: 2)]
end
subgraph OSPool2 [OSPool 2]
H2_3[/Compute node: 3/]
H2_4[/Compute node: 4/]
H3_3[(File storage: 3)]
H3_4[(File storage: 4)]
end
subgraph OSPooln [OSPool n]
H2_n[/Compute node: n/]
H2_90[/Compute node: 90/]
H3_n[(File storage: n)]
H3_90[(File storage: 90)]
end

H1<-->H2_1
H1<-->H2_2
H1<-->H2_3
H1<-->H2_4
H1<-->H2_n
H1<-->H2_90

H2_1<-->H3_1
H2_2<-->H3_2
H2_3<-->H3_3
H2_4<-->H3_4
H2_n<-->H3_n
H2_90<-->H3_90

H1<-->H3

H3~~~H2_1
H3~~~H2_2
H3~~~H2_3
H3~~~H2_4
H3~~~H2_n
H3~~~H2_90
style Local stroke-width:3px
style OSG stroke-width:3px,stroke-dasharray: 5 5
style OSPool1 stroke-width:3px,stroke-dasharray: 5 5
style OSPool2 stroke-width:3px,stroke-dasharray: 5 5
style OSPooln stroke-width:3px,stroke-dasharray: 5 5
```
:::


::: {.absolute bottom="5%" width="100%" }
Documentation of this example using OSG can be found on our [GitHub website](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/ss3-osg.html){preview-link="true"}.
:::

::: {.fragment .fade-in fragment-index=1}
::: {.absolute left="70%" right="10%" top="0%" style="font-color: #ffffff; font-size:0.65em; padding: 0.25em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[**Biggest difference**: no shared file system between compute nodes]{.bg} 
:::
:::

## Example results {.smaller}

```{r}
#| eval: true
#| echo: false
#| output: false
library(data.table)
library(magrittr)
proj_dir = this.path::this.proj()
comptime_dt = fread(file=paste0(proj_dir,"/examples/hera/ss3/output/comptime_dt.csv"))
comptime_dt_minus = comptime_dt[index!=79]
ssb_dt = fread(file=paste0(proj_dir,"/examples/hera/ss3/output/ssb_dt.csv"))
retro_dt = fread(file=paste0(proj_dir,"/examples/hera/ss3/output/retro_dt.csv"))
```


::: columns
::: {.column width="33%"}
The example ran 90 jobs (18 test models $\times$ 5 runs each; base + 4 *peels*), with only one job 'timing out' at 1-hour limit.

$~$
$~$

::: {.fragment .fade-in fragment-index=1}
Excluding the job that timed out the `r nrow(comptime_dt_minus)` jobs run on Hera completed [`r round(sum(comptime_dt_minus$hera_runtime)/60,digits=2)` hours]{.fragment .hl-blue fragment-index=2} of calculations (`r round(mean(comptime_dt_minus$hera_runtime),digits=2)` minutes per job) in an elapsed time of [`r round(as.numeric(abs(difftime(min(comptime_dt_minus$hera_start),max(comptime_dt_minus$hera_end),units="mins"))),digits=2)` minutes]{.fragment .hl-blue fragment-index=3} or $\sim$ `r round(1/(as.numeric(abs(difftime(min(comptime_dt_minus$hera_start),max(comptime_dt_minus$hera_end),units="mins")))/sum(comptime_dt_minus$hera_runtime)))` $\times$ faster.
:::

:::
:::

::: {.fragment .fade-out fragment-index=1}
![](static/hera-ss3-retro.png){.absolute top="10%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" right="0%" style="font-color: #323C46; font-size:0.75em;"}
Depletion estimates across retrospective peels from the SS3 testing model suite examples. Mohn's $\rho$ values are printed in each panel.
:::
:::

::: {.fragment .fade-in fragment-index=1}
![](static/hera-ss3-elapsed.png){.absolute top="10%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.75em;"}
Start and stop time for jobs run on Hera, excluding the job that timed out.
:::
:::

::: {.fragment .fade-in fragment-index=4}
::: {.absolute left="10%" top="40%" style="font-color: #ffffff; font-size:2em; padding: 0.25em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Is this 'time-savings' worth it?]{.bg} 
:::
:::

## Benchmark testing
</br>

Run the same large job array on both OSG and Hera

</br>

Build Apptainer container to replicate an identical software environment on both OSG and Hera

</br>

Make sure we can run SS3 and R with non-default packages


## Benchmark testing {.smaller}

</br>

::: {.fragment .fade-out fragment-index=1}
Using a baseline SS3 file, run 500 alternative models with different fixed parameter values of natural mortality and steepness (uses SS3 and R; [r4ss](https://r4ss.github.io/r4ss/){preview-link="true"})
:::


::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
::: {.absolute top="20%" left="1%" right="67%" bottom="0%"}
Use the delta-MVLN approach to generate uncertainty in predictions so that models can be combined in an ensemble (uses R; [ss3diags](https://pifscstockassessments.github.io/ss3diags/){preview-link="true"})
:::
:::
:::


::: {.fragment .fade-in fragment-index=2}
::: {.absolute top="20%" left="1%" right="67%" bottom="0%"}
Run 5 retrospective peels ($t-1$ to $t-5$) for each of the 500 models and calculate Mohn's $\rho$

</br>

[*Note*:]{.blue} Retrospective peels were treated as separate jobs for the purpose of the benchmark testing giving [3000 unique jobs]{.fragment .hl-blue}.
:::
:::

::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
![](static/fig-ensemble.png){.absolute top="12%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.65em;"}
Stock status plots from the model ensemble: [A]{.blue} spawning biomass relative to the spawning biomass at MSY, and [B]{.blue} fishing mortality relative to the fishing mortality at MSY. The median is showed in the solid line, darker band shows the 50th percentile and lighter band the 80th percentile.
:::
:::
:::

::: {.fragment .fade-in fragment-index=2}
![](static/fig-retro-ssb.png){.absolute top="12%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.65em;"}
Mohn's $\rho$ for alternative parameter combinations of natural mortality (M) and steepness (h). The solid black lines denote the original M (vertical line) and steepness (horizontal line).
:::
:::

## Benchmark testing - OSG {.smaller}

::: columns
::: {.column width="33%"}
All 3000 jobs hit the queue at the same time from a single array job submission and began executing almost immediately


</br>

::: {.fragment .fade-in fragment-index=1}
Small fraction of jobs had bad file transfer and had to be relaunched
:::

</br>

::: {.fragment .fade-in fragment-index=2}
Total computation time was [$\sim$ 25 days]{.fragment .hl-blue fragment-index=3}, but elapsed time was [$\sim$ 3.5 hours]{.fragment .hl-blue fragment-index=4} (166 $\times$ faster)
:::

:::
:::

![](static/fig-osg-elapsed.png){.absolute top="12%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.75em;"}
Start and stop time for jobs run on OpenScienceGrid (OSG).
:::

::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
::: {.absolute top="17.5%" bottom="77%" left="57.5%" right="-2.5%" style="border: solid; border-radius: 15px; border-width: thick; border-color: #003087;"}

:::
:::
:::

## Benchmark testing - Hera (as HTC) {.smaller}


::: {.fragment .fade-out fragment-index=1}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%"}
Queue and *job_array_id limits* required multiple (staggered) job submissions
:::
:::

::: {.fragment .fade-in fragment-index=1}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%" style="font-size:0.85em;"}
Large proportion of jobs suffered from resource competition during memory/disk intensive portion of SS3 calculations (SD calcs) and produced incomplete outputs.
:::

::: {.fragment .fade-in fragment-index=2}
::: {.absolute left="1%" top="50%" right="67%" style="font-color: #ffffff; font-size:0.75em; padding: 0.25em 1em; background-color: #0085CA; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}

[Note]{.blue} [SS3 does not appear to crash/trigger an error when it runs out of memory/disk but instead writes out available output which *could* appear complete.]{.bg} 
:::
:::
:::


![](static/fig-hera-elapsed.png){.absolute top="12%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.75em;"}
Start and stop time for jobs run on NOAA Hera.
:::

## Benchmark testing - Hera (parallel) {.smaller}

::: {.fragment .fade-out fragment-index=1}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%"}
The Hera workflow was re-configured to run parallel jobs within 15 compute nodes using the *gnu* parallel utility[^2].
:::
:::

[^2]: [Note]{.blue} this is how the earlier SS3 [example](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/ss3-hera.html){preview-link="true"} was formulated.


::: {.fragment .fade-out fragment-index=2}
::: {.fragment .fade-in fragment-index=1}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%"}
All jobs hit the queue at the same time and executed as resources became available within each node.

</br>

Each node had 200 jobs allocated to it spread out over 40 CPUs resulting in the [$\sim$ 5 distinct *waves*]{.blue} of job execution.
:::
:::
:::



::: {.fragment .fade-out fragment-index=5}
::: {.fragment .fade-in fragment-index=2}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%"}
Total computation time for 3000 jobs was [$\sim$ 25.5 days]{.fragment .hl-blue fragment-index=3}, but elapsed time was [$\sim$ 1.75 hours]{.fragment .hl-blue fragment-index=4}
:::
:::
:::


::: {.fragment .fade-in fragment-index=5}
::: {.absolute top="12%" left="1%" right="67%" bottom="0%"}
2998 of 2999 ([99.99 %]{.blue}) completed models produced identical output to OSG
:::
:::


![](static/fig-hera-par-elapsed.png){.absolute top="12%" left="37.5%" height="65%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 5px;"}

::: {.absolute top="80%" left="37.5%" style="font-color: #323C46; font-size:0.75em;"}
Start and stop time for jobs run on NOAA Hera using *gnu* parallel utility.
:::

## Benchmark testing - Summary {.smaller}

</br>

::: {.fragment .semi-fade-out fragment-index=1}
We have working proof-of-concept and workflows for both OSG and Hera that can result in substantial time savings
:::

</br>

::: {.fragment .semi-fade-out fragment-index=1}
Analyses are portable between computing solutions with *minimal* modifications to workflows
:::

</br>

::: {.fragment .semi-fade-out fragment-index=1}
OSG and Hera have different strengths, weaknesses, and constraints so analysts can choose which may be better suited for different tasks
:::

::: {.fragment .fade-in fragment-index=1}
::: {.absolute left="10%" top="40%" style="font-color: #ffffff; font-size:2em; padding: 0.25em 1em; background-color: #002364; box-shadow: 0 0 1rem 0 rgba(0, 0, 0, .5); border-radius: 15px;"}
[Is this 'time-savings' worth it?]{.bg} 
:::
:::

## Getting started! {.smaller}

::: columns
::: {.column width="45%"}
[OpenScienceGrid (OSG)]{.blue}

</br>

1. Reach out to [OSPool](https://portal.osg-htc.org/documentation/overview/account_setup/registration-and-login/){preview-link="true"} staff and apply for access.

2. Run some models!

:::
::: {.column width="45%"}
[NOAA Hera]{.blue}

</br>

1. Apply for an [RDHPCS account](https://docs.rdhpcs.noaa.gov/accounts/accounts_and_projects.html#applying-for-a-user-account){preview-link="true"} at the [Account Information Management](https://aim.rdhpcs.noaa.gov/) (AIM) website (CAC login required).

2. [Request access to a RDHPCS project](https://docs.rdhpcs.noaa.gov/accounts/accounts_and_projects.html#request-access-to-rdhpcs-projects){preview-link="true"}. First time users can request access to the *htc4sa* project to test out Hera before requesting their own project allocation.

3. Run some models!

:::
:::

## Closing thoughts

</br>

::: incremental
- Limitations and bottle-necks
- What have we not discussed?
- What about the cloud?
- Integrating with [Open Science]{.blue} workflows
:::

## Acknowledgements {.smaller}
</br>

Thank you to Howard Townsend for helping get the RDHPCS *htc4sa* project off the ground.

</br>

Thank you also to Help Desk staff at both OSG OSPool and NOAA RDHPCS for helping troubleshoot and refine job array workflows using HTCondor and Slurm, respectively. 

</br>

OSG workflow development and benchmark testing was conducted using services provided by the OSG Consortium [@osg06;@osg07;@osg09;@osg15], which is supported by the National Science Foundation awards #2030508 and #1836650.

## Contact us

![](static/nd.jpg){.absolute top="12.5%" left="2%" width="20%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 30px;"}

![](static/mo2.jpeg){.absolute top="50%" left="2%" width="20%" style="max-height: unset; max-width: unset; box-shadow: 0 0 2rem 0 rgba(0, 0, 0, .5); border-radius: 30px;"}

::: {.absolute left="30%" top="12.5%" style="font-size:1em; "}
[Nicholas Ducharme-Barth](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/web-about-nd.html){preview-link="true"}

[nicholas.ducharme-barth [at]{.blue} noaa.gov]{.font-small}
:::

::: {.absolute left="30%" top="50%" style="font-size:1em; "}
[Megumi Oshima](https://moshima-pifsc.github.io/NSASS-HTC-HPC-Computing/assets/web-about-mo.html){preview-link="true"}

[megumi.oshima [at]{.blue} noaa.gov]{.font-small}
:::


## References

::: {#refs}
:::
