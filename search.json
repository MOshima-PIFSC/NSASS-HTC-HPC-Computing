[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This repository contains examples and documentation for accessing and applying existing research computing resources available to NOAA Fisheries staff. Example code and documentation were presented as a part of the National Stock Assessment Seminar series (slides).\n\n\n\n Back to top",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "assets/web-slides.html",
    "href": "assets/web-slides.html",
    "title": "Seminar slides",
    "section": "",
    "text": "Seminar slides from the NOAA National Stock Assessment Science Seminar Series presentation.\n    View slides in full screen\n       \n      \n    \n  \n\n\n\n Back to top",
    "crumbs": [
      "Seminar slides"
    ]
  },
  {
    "objectID": "assets/web-about-mo.html",
    "href": "assets/web-about-mo.html",
    "title": "Megumi Oshima",
    "section": "",
    "text": "Megumi Oshima has been working at the Pacific Islands Fisheries Science Center since 2021. She works mostly on domestic and territorial bottomfish stocks and is interested in Openscience and creating reproducible and transparent workflows. Before joining PIFSC, she was a graduate student at University of Southern Mississippi where she got her PhD in Coastal Sciences.\n\n\n Back to top",
    "crumbs": [
      "Contact us",
      "Megumi Oshima"
    ]
  },
  {
    "objectID": "assets/presentation.html#test-slide",
    "href": "assets/presentation.html#test-slide",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "Test slide",
    "text": "Test slide\n\nThis is a test link.\nThis is some emphasized text.\nHere is some text that is hidden and waiting for later."
  },
  {
    "objectID": "assets/presentation.html#test-slide-1",
    "href": "assets/presentation.html#test-slide-1",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "Test slide",
    "text": "Test slide\n\nThis is a test link.\nThis is some emphasized text.\nHere is some text that is hidden and waiting for later. And now it appears!"
  },
  {
    "objectID": "assets/presentation.html#what-do-we-want-to-do",
    "href": "assets/presentation.html#what-do-we-want-to-do",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "What do we want to do?",
    "text": "What do we want to do?\n\n\nLeverage high-throughput or high-performance computing solutions to run stock assessment models\n\n\nRun more/bigger models in less time"
  },
  {
    "objectID": "assets/presentation.html#how-can-we-do-this",
    "href": "assets/presentation.html#how-can-we-do-this",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "How can we do this?",
    "text": "How can we do this?\n\n\n\nHigh-throughput computing (HTC)\n\nHigh-performance computing (HPC)"
  },
  {
    "objectID": "assets/presentation.html#why-use-htchpc-computing",
    "href": "assets/presentation.html#why-use-htchpc-computing",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "Why use HTC/HPC computing?",
    "text": "Why use HTC/HPC computing?\n\n\nEfficiency\nReproducibility\nDocumentation\nTransparency\nAutomation ?"
  },
  {
    "objectID": "assets/presentation.html#workflow",
    "href": "assets/presentation.html#workflow",
    "title": "Operationalizing available research computing resources for stock assessment",
    "section": "Workflow",
    "text": "Workflow\n\n\ncreate container\ncreate scripts\ntransfer files\nsubmit jobs\ntransfer files back to local machine\n\n\n\n\n\n\nNational Stock Assessment Science Seminar"
  },
  {
    "objectID": "assets/hera_documentation.html",
    "href": "assets/hera_documentation.html",
    "title": "Working with NOAA HPC Hera",
    "section": "",
    "text": "Open a terminal window (.e.g, command prompt or PowerShell), then open an ssh tunnel to Hera by using the following command:\n\nssh -m hmac-sha2-256-etm@openssh.com User.Name@hera-rsa.bastion.rdhpcs.noaa.gov -p22\n\nReplace User.Name with your NOAA HPC account name, and bastion with either boulder or princeton depending on which ‘bastion’ you wish to log-in through. Note that the flag -p22 specifies opening port 22 and is optional. When prompted, put in your password followed by the RSA authentication code:\n\nXXXXXXXXRSACODE\n\nIf you see the following then you have connected successfully:\n\n________________________________________________________\n|                                                        |\n|                                                        |\n|  Welcome to the Hera High Performance Computing system |\n|                                                        |\n|        This system is located in Fairmont, WV          |\n|                                                        |\n|          Please Submit Helpdesk Requests to:           |\n|               rdhpcs.hera.help@noaa.gov                |\n|                                                        |\n|________________________________________________________|\n\nNote that you will also see the following terminal output upon connecting:\n\nLocal port XXXXX forwarded to remote host.\nRemote port YYYYY forwarded to local host.\n\nWhere XXXXX and YYYYY are your 4-5 digit port forwarding numbers. Make note of what your local port number (XXXXX) is since this will be used for scp file transfer using an ssh tunnel.",
    "crumbs": [
      "Documentation",
      "Working with NOAA HPC Hera"
    ]
  },
  {
    "objectID": "assets/hera_documentation.html#connecting-to-hera-via-ssh",
    "href": "assets/hera_documentation.html#connecting-to-hera-via-ssh",
    "title": "Working with NOAA HPC Hera",
    "section": "",
    "text": "Open a terminal window (.e.g, command prompt or PowerShell), then open an ssh tunnel to Hera by using the following command:\n\nssh -m hmac-sha2-256-etm@openssh.com User.Name@hera-rsa.bastion.rdhpcs.noaa.gov -p22\n\nReplace User.Name with your NOAA HPC account name, and bastion with either boulder or princeton depending on which ‘bastion’ you wish to log-in through. Note that the flag -p22 specifies opening port 22 and is optional. When prompted, put in your password followed by the RSA authentication code:\n\nXXXXXXXXRSACODE\n\nIf you see the following then you have connected successfully:\n\n________________________________________________________\n|                                                        |\n|                                                        |\n|  Welcome to the Hera High Performance Computing system |\n|                                                        |\n|        This system is located in Fairmont, WV          |\n|                                                        |\n|          Please Submit Helpdesk Requests to:           |\n|               rdhpcs.hera.help@noaa.gov                |\n|                                                        |\n|________________________________________________________|\n\nNote that you will also see the following terminal output upon connecting:\n\nLocal port XXXXX forwarded to remote host.\nRemote port YYYYY forwarded to local host.\n\nWhere XXXXX and YYYYY are your 4-5 digit port forwarding numbers. Make note of what your local port number (XXXXX) is since this will be used for scp file transfer using an ssh tunnel.",
    "crumbs": [
      "Documentation",
      "Working with NOAA HPC Hera"
    ]
  },
  {
    "objectID": "assets/hera_documentation.html#transferring-files-tofrom-hera",
    "href": "assets/hera_documentation.html#transferring-files-tofrom-hera",
    "title": "Working with NOAA HPC Hera",
    "section": "2 Transferring files to/from Hera",
    "text": "2 Transferring files to/from Hera\n\n2.1 via scp using data transfer node (DTN)\nInformation in this section is largely based on this wiki(CAC login required). File transfer using a DTN is only possible from machines within the noaa.gov domain (VPN ok), and can only transfer files to the scratch directory. However, this is ok since it is recommended that input/output data files are stored in the scratch directory. Using a DTN is faster than using the ssh tunnel.\n\n\n\n\n\n\nNote\n\n\n\nThe scratch1/NMFS/project_name/ directory is a shared space (shared access and shared disk space) for all users of a project. Rather than dumping files into the root project directory (e.g., project_name/) it is better to place them in your own sub-directory. Since this sub-directory structure does not already exist you will need to log into Hera and create it:\n\nmkdir scratch1/NMFS/project_name/User.Name/\n\nThis will avoid over-writing other users’ work.\n\n\nFile transfer takes place via scp using:\n\nscp /path/to/local/file User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/project_name/User.Name/\n\nand replace User.Name and project_name with your HPC account name and project.\nIf trying to transfer from a machine not within the NOAA domain (or on the VPN) you can use scp with an untrusted DTN:\n\nscp /path/to/local/file User.Name@udtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/data_untrusted/User.Name/\n\nNote that dtn-hera was changed to udtn-hera. As before replace User.Name with your HPC account name. Since files can not stay in the data_untrusted directory we will need to log in to Hera and move it to the correct project directory on scratch. Once logged in, moving the files can be done with rsync (CAC login required), and then they can be deleted from data_untrusted by:\n\nrsync -axv /scratch1/data_untrusted/User.Name/file /scratch1/NMFS/project_name/User.Name/\nrm /scratch1/data_untrusted/User.Name/file\n\nBe sure to replace User.Name and project_name with your HPC account name and project.\nFiles can be downloaded using scp from either the trusted (dtn) or untrusted (udtn) DTN:\n\nscp User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/NMFS/project_name/User.Name/file /path/to/local/file \n\n\n\n2.2 via scp using an ssh tunnel\nInformation in this section is largely based on this wiki (CAC login required). File transfer using an ssh tunnel is possible from all locations. Using the ssh tunnel for file transfer requires a two-step process with two active terminal windows (we suggest using PowerShell):\n\nIn the first terminal window, open an ssh connection to Hera with port forwarding:\n\n\nssh -m hmac-sha2-256-etm@openssh.com -LXXXXX:localhost:XXXXX User.Name@hera-rsa.bastion.rdhpcs.noaa.gov\n\nReplace XXXXX with your local port number. As before replace User.Name and bastion.\n\nIn the second terminal window you can check to see if the tunnel was properly created:\n\n\nssh -p XXXXX User.Name@localhost\n\nif you get prompted for your password then success! Press CONTROL+C to ignore this prompt. Staying within this 2nd terminal window use scp to transfer your file:\n\nscp -P XXXXX /path/to/local/file User.Name@localhost:/home/User.Name/\n\nThis will copy your file from your local machine into your home directory on Hera. Simply append additional directory structure to /home/User.Name/ to copy it into a sub-directory that you have created on Hera (e.g., /home/User.Name/sub/dir/). To transfer files into your scratch directory, specify the proper destination path (e.g., /scratch1/NMFS/project_name/User.Name/ where project_name is your HPC account project).\nTo download a file from Hera using scp and the ssh tunnel use the following:\n\nscp -P XXXXX User.Name@localhost:/home/User.Name/file_name /path/to/local/file",
    "crumbs": [
      "Documentation",
      "Working with NOAA HPC Hera"
    ]
  },
  {
    "objectID": "assets/web-about-nd.html",
    "href": "assets/web-about-nd.html",
    "title": "Nicholas Ducharme-Barth",
    "section": "",
    "text": "Nicholas Ducharme-Barth joined the Pacific Islands Fisheries Science Center in 2021. Previously, Nicholas worked at the Pacific Community (SPC) conducting pelagic stock assessments for the Western and Central Pacific Fisheries Commission (WCPFC). He received his B.S. in Mathematics from the College of William & Mary and his Ph. D. in Fisheries and Aquatic Sciences from the University of Florida.\n\n\n Back to top",
    "crumbs": [
      "Contact us",
      "Nicholas Ducharme-Barth"
    ]
  },
  {
    "objectID": "assets/array_hera.html",
    "href": "assets/array_hera.html",
    "title": "Working with NOAA HPC Hera",
    "section": "",
    "text": "In this example we step through submitting an array job on Hera where we want to run the same job in a number of directories. In this case the job is running a simple R script that reads in the .csv file stored in the directory, fits a linear model, and writes the paramter estimates to a .csv. We specify which directories we want to run jobs in as a part of the job-array using a text file to specify the directory path names on Hera. ###TODO: update links\nThe hera/array_lm example can be set-up either by cloning the repository git clone https://github.com/N-DucharmeBarth-NOAA/noaa-hpc-hera.git, or stepping through the following code:",
    "crumbs": [
      "Documentation",
      "Submitting an array job"
    ]
  },
  {
    "objectID": "assets/array_hera.html#setup-data-inputs-and-directories",
    "href": "assets/array_hera.html#setup-data-inputs-and-directories",
    "title": "Working with NOAA HPC Hera",
    "section": "1 Setup data inputs and directories",
    "text": "1 Setup data inputs and directories\n\nDefine a relative path, we are starting from the root directory of this project.\n\n\nproj_dir = this.path::this.proj()\nhera_project = \"Project/Name/User.Name/\"\n\n\nDefine directory names for each run.\n\n\ndir_name = paste0(\"rep_0\", 0:9)\n\n\nIterate across directories, create them, and then write a simple .csv file into them containing data to fit a linear model.\n\n\nfor(i in seq_along(dir_name)){\n    \n    if(!file.exists(file.path(proj_dir, \"example\", \"hera\", \"array_lm\", \"inputs\", dir_name[i], \"data.csv\")))\n    {\n        set.seed(i)\n        dir.create(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", dir_name[i]), recursive=TRUE)\n        tmp = data.frame(x=1:1000)\n        tmp$y = (i + (0.5*i)*tmp$x) + rnorm(1000,0,i)\n        write.csv(tmp, file = file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", dir_name[i], \"data.csv\"))\n    }\n}\n\n\nWrite an R script to read in the data, run a linear model, and report back the estimated parameters.\n\n\nif(!file.exists(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", \"run_lm_hera_array.r\"))){\n    script_lines = c(\"tmp=read.csv('data.csv')\", \n    \"fit=lm(y~x,data=tmp)\", \n    \"out = data.frame(par=unname(fit$coefficients))\", \n    \"write.csv(out,file='par.csv')\"\n    )\n    writeLines(script_lines, con = file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", \"run_lm_hera_array.r\"))\n}\n\n\nWrite a text file containing the full path names for where the directories will be on Hera.\n\n\nif(!file.exists(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", \"hera_job_directories.txt\"))){\n    dir_lines = paste0(\"/scratch1/\", hera_project, \"array_hera/\", dir_name, \"/\")\n    writeLines(dir_lines, con = file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", \"hera_job_directories.txt\"))\n}\n\n\nCompress the entire array_lm/ directory as a tar.gz file upload.array_lm.tar.gz. This simplifies the number of steps needed for file transfers.\n\n\nshell(paste0(\"powershell cd \", file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\"), \";tar -czf upload.array_lm.tar.gz array_lm \"))",
    "crumbs": [
      "Documentation",
      "Submitting an array job"
    ]
  },
  {
    "objectID": "assets/array_hera.html#hera-workflow",
    "href": "assets/array_hera.html#hera-workflow",
    "title": "Working with NOAA HPC Hera",
    "section": "2 Hera workflow",
    "text": "2 Hera workflow\n\nConnect to Hera\n\nOpen a PowerShell terminal and connect to Hera. This terminal will be your remote workstation, call it Terminal A. You will be prompted for your password and RSA passcode.\n\nssh -m hmac-sha2-256-etm@openssh.com User.Name@hera-rsa.boulder.rdhpcs.noaa.gov -p22\n\n\nCreate directories\n\nIn Terminal A navigate to the project directory on scratch1 and create some directories. If using a shared directory such as htc4sa/, make a directory to save your work within this directory (.e.g., User.Name/). Change your working directory to this directory. We will upload our SLURM submit script into submit_scripts/ and write our SLURM log files to logs/.\n\n# navigate to project directory\ncd /scratch1/Project/Name/\n# create new directory\nmkdir User.Name/\n# navigate into new directory\ncd User.Name/\n# create directory for SLURM scripts and logs\nmkdir submit_scripts/\nmkdir logs/\n\n\nTransfer files\n\nOpen a second PowerShell terminal in the noaa-hpc-hera directory on your machine. This will be your local workstation, call it Terminal B. Use this terminal window to upload via scp the needed files (examples/hera/array_lm/inputs/upload.array_lm.tar.gz and examples/hera/array_lm/slurm_scripts/submit_array_lm.sh) to Hera. The upload.array_lm.tar.gz will be uploaded to your directory within the project directory on scratch1 and the submit script submit_array_lm.sh will be uploaded to the submit_scripts directory. Make sure your VPN is active when attempting to upload using the DTN. You will be prompted for your RSA passcode after each scp command.\n\nscp examples/hera/array_lm/inputs/upload.array_lm.tar.gz User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/Project/Name/User.Name\n\n\n\n\n\n\n\nCoding alert!\n\n\n\nIn submit_array_lm.sh you will need to change the following before you upload and run the script:\n\nLine 5: change account name to the name of your project. If you are using the NOAA htc4sa project, it would be htc4sa.\nLine 9: /scratch1/Project/Name/User.Name/logs/ to the location you created for logs/ above.\nLine 10: Change to your email address.\nLine 24: Make sure that this line points to the location on Hera that you uploaded hera_job_directories.txt to. hera_job_directories.txt is located in the examples/hera/array_lm/inputs directory that was uploaded as a part of upload.array_lm.tar.gz.\nLine 37: Make sure that this line points to the location on Hera that you uploaded run_lm_hera_array.r to. run_lm_hera_array.r is located in the examples/hera/array_lm/inputs directory that was uploaded as a part of upload.array_lm.tar.gz.\n\n\n\n\nscp examples/hera/array_lm/slurm_scripts/submit_array_lm.sh User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/Project/Name/User.Name/submit_scripts/\n\n\nUn-tar files\n\nBack in Terminal A untar the uploaded directory.\n\ntar -xzf upload.array_lm.tar.gz\n\n\nPrep files to be read on Hera\n\nMake sure files that will be read/executed have unix line endings:\n\ndos2unix array_lm/inputs/run_lm_hera_array.r array_lm/hera_job_directories.txt array_lm/slurm_scripts/submit_array_lm.sh\n\n\nSubmit job\n\nNow you are ready to submit the SLURM submission script submit_array_lm.sh.\n\nsbatch submit_scripts/submit_array_lm.sh\n\nAs part of this job script, it cleans the directories specified in hera_job_directories.txt of the input file data.csv. The output is a compressed tar.gz containing the output produced by run_lm_hera_array.r (par.csv) and runtime.txt which logs the job start, end, and runtime. You can check your job status using squeue but this job should complete in a few seconds.\n\nsqueue -u User.Name\n\n\nDownload results\n\nBefore sending back the results you need to compress array_lm.\n\ntar -czf download.array_lm.tar.gz array_lm\n\nMoving back to Terminal B you can download the results, but first you create a directory for it to be downloaded into. This can be done in R:\n\ndir.create(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"output\"), recursive=TRUE, showWarnings = FALSE)\n\nNow you can use scp in Terminal B to download download.array_lm.tar.gz into examples/hera/array_lm/output\n\nscp User.Name@dtn-hera.fairmont.rdhpcs.noaa.gov:/scratch1/Project/Name/User.Name/download.array_lm.tar.gz examples/hera/array_lm/output/\n\nMove into examples/hera/array_lm/output/ and untar downloaded results.\n\n# navigate to output directory\ncd examples/hera/array_lm/output/\n# untar results\ntar -xzf download.array_lm.tar.gz",
    "crumbs": [
      "Documentation",
      "Submitting an array job"
    ]
  },
  {
    "objectID": "assets/array_hera.html#process-the-output",
    "href": "assets/array_hera.html#process-the-output",
    "title": "Working with NOAA HPC Hera",
    "section": "3 Process the output",
    "text": "3 Process the output\nIn R, iterate through the sub-directories of the input and output data to extract the results of the linear model fits, and the model run time information.\n\n\nShow code\nlibrary(data.table)\nlibrary(magrittr)\n\ninput_data.list = as.list(rep(NA,10))\noutput_data.list = as.list(rep(NA,10))\nruntime_data.list = as.list(rep(NA,10))\n\n##TODO: change paths here to match directory names\nfor(i in seq_along(dir_name)){\n    # get input data\n        input_data.list[[i]] = fread(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"inputs\", dir_name[i],\"data.csv\")) %&gt;%\n            .[,.(x,y)] %&gt;%\n            .[,model := factor(as.character(i),levels=as.character(1:10))] %&gt;%\n            .[,.(model,x,y)]\n    \n    # untar results\n        system(paste0(\"powershell cd \", file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"output\", dir_name[i],\"/\"), \";tar -xzf output.tar.gz\"))\n\n    # get output\n        output_data.list[[i]] = fread(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"output\", dir_name[i],\"par.csv\")) %&gt;%\n            .[,.(par)] %&gt;%\n            .[,model := factor(as.character(i),levels=as.character(1:10))] %&gt;%\n            .[,.(model,par)] %&gt;%\n            melt(.,id.vars=\"model\") %&gt;%\n            .[,variable:=c(\"intercept\",\"slope\")] %&gt;%\n            dcast(.,model ~ variable) %&gt;%\n            merge(.,input_data.list[[i]][,.(model,x)],by=\"model\") %&gt;%\n            .[,pred_y := intercept+slope*x] %&gt;%\n            .[,.(model,x,pred_y)]\n    # get time\n        runtime_data.list[[i]] = readLines(file.path(proj_dir, \"examples\", \"hera\", \"array_lm\", \"output\", dir_name[i],\"runtime.txt\")) %&gt;%\n            gsub(\".*?([0-9]+).*\", \"\\\\1\", .) %&gt;%\n            as.numeric(.) %&gt;%\n            as.data.table(.) %&gt;%\n            setnames(.,\".\",\"time\") %&gt;%\n            .[,model := factor(as.character(i),levels=as.character(1:10))] %&gt;%\n            melt(.,id.vars=\"model\") %&gt;%\n            .[,variable:=c(\"start\",\"end\",\"runtime\")] %&gt;%\n            dcast(.,model ~ variable) %&gt;%\n            .[,.(model,start,end,runtime)]\n}\n\ninput_data = rbindlist(input_data.list)\noutput_data = rbindlist(output_data.list)\nruntime_data = rbindlist(runtime_data.list)\n\n\nThe jobs started execution at 2023-05-31 00:49:56 and all finished by 2023-05-31 00:49:57 for an elapsed runtime of 1 seconds and a total computation time of 5 seconds. Use of Hera resulted in a job completing 5\\(\\times\\) faster. Figure 1 shows the simulated data and estimated linear fits for each model run in the job-array.\n\n\nShow code\nlibrary(ggplot2)\ninput_data %&gt;%\nggplot() +\ngeom_point(aes(x=x,y=y,fill=model),alpha=0.05,size=5,shape=21) +\ngeom_line(data=output_data,aes(x=x,y=pred_y,color=model),linewidth=2)\n\n\n\n\n\n\n\n\nFigure 1: Linear model fits from the 10 models run.",
    "crumbs": [
      "Documentation",
      "Submitting an array job"
    ]
  }
]